# -*- coding: utf-8 -*-
"""NationalAnthemToInunoOmawarisan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wd2qTXhYWL4g-3QKFksrMS_D_WztVRkN
"""

!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev
!pip3 install -qU pyfluidsynth pretty_midi
!pip3 install -qU magenta





!gsutil -q -m cp -R gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/mel_2bar_big.ckpt.* /content/

from magenta.models.music_vae import configs
from magenta.models.music_vae.trained_model import TrainedModel

# モデルの初期化
music_vae = TrainedModel(
      configs.CONFIG_MAP["cat-mel_2bar_big"], 
      batch_size=4,  # 一度に処理するデータ数
      checkpoint_dir_or_path="/content/mel_2bar_big.ckpt")

import note_seq

generated = music_vae.sample(n=5,  # 生成数
                             length=64,  # ステップ数
                             temperature=0.5)  # 温度

for ns in generated:
    note_seq.plot_sequence(ns)
    note_seq.play_sequence(ns, synth=note_seq.fluidsynth)

"""#出だしは「君が代」、終わりは「犬のおまわりさん」
1.   「君が代」は出だしの２小節で誰もがわかる曲だから選んだ
2.   「犬のおまわりさん」は最後の２小節でほとんどの人が認識すると考えて選んだ


"""

import magenta
import note_seq
from note_seq.protobuf import music_pb2
# 最初のNoteSeqence
kira2_start = music_pb2.NoteSequence()

kira2_start.notes.add(pitch=62, start_time=0.0, end_time=0.4, velocity=80)
kira2_start.notes.add(pitch=60, start_time=0.4, end_time=0.8, velocity=80)
kira2_start.notes.add(pitch=62, start_time=0.8, end_time=1.2, velocity=80)
kira2_start.notes.add(pitch=64, start_time=1.2, end_time=1.6, velocity=80)
kira2_start.notes.add(pitch=67, start_time=1.6, end_time=2.0, velocity=80)
kira2_start.notes.add(pitch=64, start_time=2.0, end_time=2.4, velocity=80)
kira2_start.notes.add(pitch=62, start_time=2.4, end_time=3.2, velocity=80)
kira2_start.notes.add(pitch=64, start_time=3.2, end_time=3.6, velocity=80)
kira2_start.notes.add(pitch=67, start_time=3.6, end_time=4.0, velocity=80)
kira2_start.notes.add(pitch=69, start_time=4.0, end_time=4.4, velocity=80)
kira2_start.notes.add(pitch=67, start_time=4.4, end_time=4.6, velocity=80)
kira2_start.notes.add(pitch=69, start_time=4.6, end_time=4.8, velocity=80)
kira2_start.notes.add(pitch=74, start_time=4.8, end_time=5.2, velocity=80)
kira2_start.notes.add(pitch=71, start_time=5.2, end_time=5.6, velocity=80)
kira2_start.notes.add(pitch=69, start_time=5.6, end_time=6.0, velocity=80)
kira2_start.notes.add(pitch=67, start_time=6.0, end_time=6.4, velocity=80)

kira2_start.total_time = 6.4 
kira2_start.tempos.add(qpm=75);

note_seq.plot_sequence(kira2_start)
note_seq.play_sequence(kira2_start, synth=note_seq.fluidsynth)

# 最後のNoteSeqence
kira2_end = music_pb2.NoteSequence()

kira2_end.notes.add(pitch=69, start_time=0.0, end_time=0.2, velocity=80)
kira2_end.notes.add(pitch=74, start_time=0.2, end_time=0.4, velocity=80)
kira2_end.notes.add(pitch=72, start_time=0.4, end_time=0.6, velocity=80)
kira2_end.notes.add(pitch=69, start_time=0.6, end_time=0.8, velocity=80)
kira2_end.notes.add(pitch=65, start_time=0.8, end_time=1.6, velocity=80)

kira2_end.notes.add(pitch=67, start_time=1.6, end_time=1.8, velocity=80)
kira2_end.notes.add(pitch=69, start_time=1.8, end_time=2.2, velocity=80)
kira2_end.notes.add(pitch=65, start_time=2.2, end_time=2.4, velocity=80)
kira2_end.notes.add(pitch=62, start_time=2.4, end_time=2.6, velocity=80)
kira2_end.notes.add(pitch=65, start_time=2.6, end_time=3.0, velocity=80)
kira2_end.notes.add(pitch=67, start_time=3.0, end_time=3.2, velocity=80)

kira2_end.notes.add(pitch=69, start_time=3.2, end_time=3.6, velocity=80)
kira2_end.notes.add(pitch=65, start_time=3.6, end_time=4.0, velocity=80)
kira2_end.notes.add(pitch=67, start_time=4.0, end_time=4.2, velocity=80)
kira2_end.notes.add(pitch=74, start_time=4.2, end_time=4.8, velocity=80)
kira2_end.notes.add(pitch=72, start_time=4.8, end_time=5.2, velocity=80)
kira2_end.notes.add(pitch=67, start_time=5.2, end_time=5.6, velocity=80)
kira2_end.notes.add(pitch=69, start_time=5.6, end_time=5.8, velocity=80)
kira2_end.notes.add(pitch=65, start_time=5.8, end_time=6.4, velocity=80) 

kira2_end.total_time = 6.4
kira2_end.tempos.add(qpm=75); 

note_seq.plot_sequence(kira2_end)
note_seq.play_sequence(kira2_end, synth=note_seq.fluidsynth)  # NoteSequenceの再生

"""#君が代と全く趣の異なる犬のおまわりさんをどうやってinterpolateするかお手並み拝見
*    時間は結果を早く知りたいので短く設定
*   終わりの部分のアレンジが思ったより多い、、、のは何故か？



"""

n_seq = 3  # 曲のNoteSeqence数（最初と最後を含む）

# NoteSeqenceを複数生成し、リストに格納
gen_seq = music_vae.interpolate(
    kira2_start,  # 最初のNoteSeqence
    kira2_end,  # 最後のNoteSeqence
    num_steps=n_seq,
    length=32)

# NoteSeqenceを全て結合し、1つの曲に
interp_seq = note_seq.sequences_lib.concatenate_sequences(gen_seq)

note_seq.plot_sequence(interp_seq)
note_seq.play_sequence(interp_seq, synth=note_seq.fluidsynth)